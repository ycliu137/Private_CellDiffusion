"""
Snakemake workflow for k_mnn and n_edges_per_node hyperparameter optimization pipeline
Note: n_edges_per_node is set equal to k_mnn for each test
"""
import os
from pathlib import Path

# Load configuration
configfile: "config.yaml"

# Get datasets list from config
DATASETS = config.get("datasets", [])

# Get line plot datasets dictionary from config
LINE_PLOT_DATASETS = config.get("line_plot_datasets", {})

# Define functions for input/output paths based on dataset wildcard
def get_input_path(wildcards):
    """Get input path for a dataset"""
    # Use input_path from config as base directory, append dataset name and .h5ad
    if "data" in config and "input_path" in config["data"]:
        input_base = config["data"]["input_path"]
        # Ensure path ends with / if it's a directory
        if not input_base.endswith(('.h5ad', '.h5')):
            if not input_base.endswith('/'):
                input_base = input_base + "/"
            input_path = input_base + f"{wildcards.dataset}.h5ad"
        else:
            # If it's already a full path to a file, use it directly (backward compatibility)
            input_path = input_base
        return input_path
    # Fallback: construct path from dataset name
    return f"../data/inputs/integration/{wildcards.dataset}.h5ad"

def get_output_base_dir():
    """Get base output directory from config"""
    if "data" in config and "output_dir" in config["data"]:
        output_base = config["data"]["output_dir"]
        if Path(output_base).is_absolute():
            return Path(output_base)
        else:
            return Path(output_base).resolve()
    # Fallback: construct path from default
    return Path("../data/outputs/hyperp_k_mnn_n_edges").resolve()

def get_output_dir(wildcards):
    """Get output directory for a dataset"""
    output_base = get_output_base_dir()
    output_dir = output_base / wildcards.dataset
    return output_dir

# Get base output directory
OUTPUT_BASE_DIR = get_output_base_dir()
OUTPUT_BASE_DIR.mkdir(parents=True, exist_ok=True)

# Get k_mnn values (list) - n_edges_per_node will be set equal to k_mnn
K_MNN_VALUES = config["integration_graph"]["k_mnn"]
if not isinstance(K_MNN_VALUES, list):
    K_MNN_VALUES = [K_MNN_VALUES]

# Helper function to get aggregate input files for a dataset
def get_aggregate_input_files(wildcards):
    """Get list of integrated files to aggregate for a dataset"""
    return [str(OUTPUT_BASE_DIR / wildcards.dataset / f"integrated_kmnn{k_mnn}.h5ad") for k_mnn in K_MNN_VALUES]

# Helper function to get line plot input tables
def get_line_plot_input_tables(wildcards):
    """Get list of scib_results_table.csv files for datasets in line_plot_datasets"""
    if not LINE_PLOT_DATASETS:
        return []
    return [str(OUTPUT_BASE_DIR / dataset_key / "scib_results_table.csv") 
            for dataset_key in LINE_PLOT_DATASETS.keys()]

# Rule all: define final outputs for all datasets
rule all:
    input:
        expand(str(OUTPUT_BASE_DIR / "{dataset}/integrated_kmnn{k_mnn}.h5ad"), dataset=DATASETS, k_mnn=K_MNN_VALUES),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/aggregated_X_dif.h5ad"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/data_with_umap.h5ad"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/umap_plot.pdf"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table.csv"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/scib_benchmarker.pkl"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table_plot.pdf"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/scib_comparison_barplot.pdf"), dataset=DATASETS)
        + ([str(OUTPUT_BASE_DIR / "scib_multi_dataset_lineplot.pdf")] if LINE_PLOT_DATASETS else [])

# Rule: Preprocess data
rule preprocess:
    input:
        h5ad = get_input_path
    output:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/preprocessed.h5ad")
    params:
        output_dir = lambda wildcards: get_output_dir(wildcards).as_posix(),
        normalized_data = config["normalized_data"],
        min_cells = config["preprocess"]["min_cells"],
        target_sum = config["preprocess"]["target_sum"],
        n_top_genes = config["preprocess"]["n_top_genes"],
        min_mean = config["preprocess"]["min_mean"],
        max_mean = config["preprocess"]["max_mean"],
        min_disp = config["preprocess"]["min_disp"]
    script:
        "scripts/preprocess.py"

# Rule: Feature encoding
rule encode_features:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/preprocessed.h5ad")
    output:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/encoded.h5ad")
    resources:
        gpu=1  # Limit GPU usage to one task at a time
    threads: 1
    params:
        output_dir = lambda wildcards: get_output_dir(wildcards).as_posix(),
        D_encode_list = config["feature_encoder"]["D_encode_list"],
        D_decode_list = config["feature_encoder"]["D_decode_list"],
        max_epoch = config["feature_encoder"]["max_epoch"],
        lr = config["feature_encoder"]["lr"],
        device = config["device"]
    script:
        "scripts/encode_features.py"

# Rule: Build integration graph with specific k_mnn (n_edges_per_node = k_mnn)
rule build_graph:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/encoded.h5ad")
    output:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/graph_kmnn{k_mnn}.h5ad")
    resources:
        gpu=1
    threads: 1
    params:
        batch_key = config["evaluation"]["batch_key"],
        k = config["integration_loss_adj"]["k"],
        k_mnn = lambda wildcards: int(wildcards.k_mnn),
        n_edges_per_node = lambda wildcards: int(wildcards.k_mnn),  # Set equal to k_mnn
        device = config["device"]
    script:
        "scripts/build_graph.py"

# Rule: Run CellDiffusion integration with specific k_mnn (n_edges_per_node = k_mnn)
rule integrate:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/graph_kmnn{k_mnn}.h5ad")
    output:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/integrated_kmnn{k_mnn}.h5ad")
    resources:
        gpu=1
    threads: 1
    params:
        max_epoch = config["integration_diffusion"]["max_epoch"],
        lr = config["integration_diffusion"]["lr"],
        num_features_diffusion = config["integration_diffusion"]["num_features_diffusion"],
        num_heads_diffusion = config["integration_diffusion"]["num_heads_diffusion"],
        num_steps_diffusion = config["integration_diffusion"]["num_steps_diffusion"],
        time_increment_diffusion = config["integration_diffusion"]["time_increment_diffusion"],
        device = config["device"],
        k_mnn = lambda wildcards: int(wildcards.k_mnn),
        n_edges_per_node = lambda wildcards: int(wildcards.k_mnn)  # Set equal to k_mnn
    script:
        "scripts/integrate.py"

# Rule: Aggregate X_dif from all k_mnn results
rule aggregate_X_dif:
    input:
        h5ad_files = get_aggregate_input_files
    output:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_X_dif.h5ad")
    script:
        "scripts/aggregate_X_dif.py"

# Rule: Compute UMAP for aggregated embeddings
rule compute_umap:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_X_dif.h5ad")
    output:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/data_with_umap.h5ad")
    params:
        use_reps = [f"X_dif_kmnn{k_mnn}" for k_mnn in K_MNN_VALUES],
        umap_keys = [f"X_umap_kmnn{k_mnn}" for k_mnn in K_MNN_VALUES],
        n_neighbors = config["umap"]["n_neighbors"],
        n_pcs = config["umap"]["n_pcs"]
    script:
        "scripts/compute_umap.py"

# Rule: Plot UMAP visualizations
rule plot_umap:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/data_with_umap.h5ad")
    output:
        pdf = str(OUTPUT_BASE_DIR / "{dataset}/umap_plot.pdf")
    params:
        umap_keys = [f"X_umap_kmnn{k_mnn}" for k_mnn in K_MNN_VALUES],
        batch_key = config["evaluation"]["batch_key"],
        label_key = config["evaluation"]["label_key"]
    script:
        "scripts/plot_umap.py"

# Rule: SCIB evaluation
rule scib_evaluation:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_X_dif.h5ad")
    output:
        results = str(OUTPUT_BASE_DIR / "{dataset}/scib_benchmarker.pkl"),
        table = str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table.csv"),
        plot = str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table_plot.pdf")
    params:
        batch_key = config["evaluation"]["batch_key"],
        label_key = config["evaluation"]["label_key"],
        n_jobs = config["scib_evaluation"]["n_jobs"]
    script:
        "scripts/scib_evaluation.py"

# Rule: Plot SCIB comparison bar plot
rule scib_evaluation_plot:
    input:
        table = str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table.csv")
    output:
        pdf = str(OUTPUT_BASE_DIR / "{dataset}/scib_comparison_barplot.pdf")
    script:
        "scripts/scib_evaluation_plot.py"

# Rule: Plot multi-dataset line plot comparing datasets across k_mnn values
rule scib_evaluation_lineplot:
    input:
        tables = get_line_plot_input_tables
    output:
        pdf = str(OUTPUT_BASE_DIR / "scib_multi_dataset_lineplot.pdf")
    params:
        dataset_dict = lambda wildcards: LINE_PLOT_DATASETS
    script:
        "scripts/scib_evaluation_lineplot.py"

