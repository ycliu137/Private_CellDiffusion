"""
Snakemake workflow for collapse diagnostic pipeline
Tests different network depths for CellDiffusion and GCN integration methods
"""
from pathlib import Path

# Load configuration
configfile: "config.yaml"

# Get datasets list from config
DATASETS = config.get("datasets", [])

# Define functions for input/output paths based on dataset wildcard
def get_input_path(wildcards):
    """Get input path for a dataset"""
    # Use input_path from config as base directory, append dataset name and .h5ad
    if "data" in config and "input_path" in config["data"]:
        input_base = config["data"]["input_path"]
        # Ensure path ends with / if it's a directory
        if not input_base.endswith(('.h5ad', '.h5')):
            if not input_base.endswith('/'):
                input_base = input_base + "/"
            input_path = input_base + f"{wildcards.dataset}.h5ad"
        else:
            # If it's already a full path to a file, use it directly (backward compatibility)
            input_path = input_base
        return input_path
    # Fallback: construct path from dataset name
    return f"../data/inputs/integration/{wildcards.dataset}.h5ad"

def get_output_base_dir():
    """Get base output directory from config"""
    if "data" in config and "output_dir" in config["data"]:
        output_base = config["data"]["output_dir"]
        if Path(output_base).is_absolute():
            return Path(output_base)
        else:
            return Path(output_base).resolve()
    # Fallback: construct path from default
    return Path("../data/outputs/collapse_diag").resolve()

def get_output_dir(wildcards):
    """Get output directory for a dataset"""
    output_base = get_output_base_dir()
    output_dir = output_base / wildcards.dataset
    return output_dir

# Get base output directory
OUTPUT_BASE_DIR = get_output_base_dir()
OUTPUT_BASE_DIR.mkdir(parents=True, exist_ok=True)

# Network layers to test (read from config)
INTEGRATION_NETWORK_LAYERS = config["integration_network_layers"]
NUM_STEPS_DIFFUSION = INTEGRATION_NETWORK_LAYERS
NUM_LAYERS_GCN = INTEGRATION_NETWORK_LAYERS

# Time increment diffusion values (paired with integration_network_layers)
TIME_INCREMENT_DIFFUSION = config["integration_diffusion"]["time_increment_diffusion"]

# Validate that time_increment_diffusion list matches integration_network_layers length
if len(TIME_INCREMENT_DIFFUSION) != len(INTEGRATION_NETWORK_LAYERS):
    raise ValueError(
        f"time_increment_diffusion list length ({len(TIME_INCREMENT_DIFFUSION)}) must match "
        f"integration_network_layers length ({len(INTEGRATION_NETWORK_LAYERS)}). "
        f"integration_network_layers={INTEGRATION_NETWORK_LAYERS}, "
        f"time_increment_diffusion={TIME_INCREMENT_DIFFUSION}"
    )

# Helper function to get time_increment_diffusion based on num_steps
def get_time_increment_for_steps(wildcards):
    """Get time_increment_diffusion value corresponding to num_steps (paired by index)"""
    num_steps = int(wildcards.num_steps)
    try:
        # Find index of num_steps in INTEGRATION_NETWORK_LAYERS
        idx = INTEGRATION_NETWORK_LAYERS.index(num_steps)
        # Return corresponding time_increment_diffusion value (paired by index)
        return TIME_INCREMENT_DIFFUSION[idx]
    except (ValueError, IndexError) as e:
        raise ValueError(f"Could not find time_increment_diffusion for num_steps={num_steps}. "
                        f"integration_network_layers={INTEGRATION_NETWORK_LAYERS}, "
                        f"time_increment_diffusion={TIME_INCREMENT_DIFFUSION}") from e

# Helper functions for aggregate rules
def get_aggregate_metrics_files(wildcards):
    """Get list of purity CSV files to aggregate for a dataset"""
    celldiffusion_files = [str(OUTPUT_BASE_DIR / wildcards.dataset / f"purity_celldiffusion_nsteps{num_steps}.csv") for num_steps in NUM_STEPS_DIFFUSION]
    gcn_files = [str(OUTPUT_BASE_DIR / wildcards.dataset / f"purity_gcn_nlayers{num_layers}.csv") for num_layers in NUM_LAYERS_GCN]
    return celldiffusion_files + gcn_files


def get_aggregate_embeddings_files(wildcards):
    """Get list of embedding h5ad files to aggregate for a dataset"""
    celldiffusion_files = [str(OUTPUT_BASE_DIR / wildcards.dataset / f"celldiffusion_nsteps{num_steps}.h5ad") for num_steps in NUM_STEPS_DIFFUSION]
    gcn_files = [str(OUTPUT_BASE_DIR / wildcards.dataset / f"gcn_nlayers{num_layers}.h5ad") for num_layers in NUM_LAYERS_GCN]
    return celldiffusion_files + gcn_files

def get_aggregate_metrics_mesenchymal_files(wildcards):
    """Get list of purity CSV files to aggregate for Mesenchymal lineage for a dataset"""
    celldiffusion_files = [str(OUTPUT_BASE_DIR / wildcards.dataset / f"purity_celldiffusion_mesenchymal_nsteps{num_steps}.csv") for num_steps in NUM_STEPS_DIFFUSION]
    gcn_files = [str(OUTPUT_BASE_DIR / wildcards.dataset / f"purity_gcn_mesenchymal_nlayers{num_layers}.csv") for num_layers in NUM_LAYERS_GCN]
    return celldiffusion_files + gcn_files

def get_aggregate_collapse_metrics_files(wildcards):
    """Get list of collapse metrics CSV files to aggregate for a dataset"""
    celldiffusion_files = [str(OUTPUT_BASE_DIR / wildcards.dataset / f"collapse_metrics_celldiffusion_nsteps{num_steps}.csv") for num_steps in NUM_STEPS_DIFFUSION]
    gcn_files = [str(OUTPUT_BASE_DIR / wildcards.dataset / f"collapse_metrics_gcn_nlayers{num_layers}.csv") for num_layers in NUM_LAYERS_GCN]
    return celldiffusion_files + gcn_files

# Rule all: define final outputs for all datasets
rule all:
    input:
        expand(str(OUTPUT_BASE_DIR / "{dataset}/aggregated_metrics.csv"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/collapse_diagnostic_plot.pdf"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/aggregated_collapse_metrics.csv"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/collapse_metrics_plot.pdf"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/aggregated_embeddings.h5ad"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table.csv"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/scib_benchmarker.pkl"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table_plot.pdf"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/scib_evaluation_lineplot.pdf"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/umap_combined_multipage.pdf"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table_mesenchymal.csv"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/scib_benchmarker_mesenchymal.pkl"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table_plot_mesenchymal.pdf"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/scib_evaluation_lineplot_mesenchymal.pdf"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/aggregated_metrics_mesenchymal.csv"), dataset=DATASETS),
        expand(str(OUTPUT_BASE_DIR / "{dataset}/collapse_diagnostic_plot_mesenchymal.pdf"), dataset=DATASETS)

# Rule: Preprocess data
rule preprocess:
    input:
        h5ad = get_input_path
    output:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/preprocessed.h5ad")
    params:
        output_dir = lambda wildcards: get_output_dir(wildcards).as_posix(),
        normalized_data = config["normalized_data"],
        min_cells = config["preprocess"]["min_cells"],
        target_sum = config["preprocess"]["target_sum"],
        n_top_genes = config["preprocess"]["n_top_genes"],
        min_mean = config["preprocess"]["min_mean"],
        max_mean = config["preprocess"]["max_mean"],
        min_disp = config["preprocess"]["min_disp"]
    script:
        "scripts/preprocess.py"

# Rule: Feature encoding
rule encode_features:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/preprocessed.h5ad")
    output:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/encoded.h5ad")
    resources:
        gpu=1
    threads: 1
    params:
        output_dir = lambda wildcards: get_output_dir(wildcards).as_posix(),
        D_encode_list = config["feature_encoder"]["D_encode_list"],
        D_decode_list = config["feature_encoder"]["D_decode_list"],
        max_epoch = config["feature_encoder"]["max_epoch"],
        lr = config["feature_encoder"]["lr"],
        device = config["device"]
    script:
        "scripts/encode_features.py"

# Rule: Build graph, integrate with CellDiffusion, and compute UMAP in one step (optimized to reduce file I/O)
rule build_integrate_umap_celldiffusion:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/encoded.h5ad")
    output:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/celldiffusion_nsteps{num_steps}.h5ad")
    resources:
        gpu=1
    threads: 1
    params:
        batch_key = config["evaluation"]["batch_key"],
        k = config["integration_loss_adj"]["k"],
        n_edges_per_node = config["integration_graph"]["n_edges_per_node"],
        k_mnn = config["integration_graph"]["k_mnn"],
        max_epoch = config["integration_diffusion"]["max_epoch"],
        lr = config["integration_diffusion"]["lr"],
        num_features_diffusion = config["integration_diffusion"]["num_features_diffusion"],
        num_heads_diffusion = config["integration_diffusion"]["num_heads_diffusion"],
        num_steps_diffusion = lambda wildcards: int(wildcards.num_steps),
        time_increment_diffusion = get_time_increment_for_steps,
        device = config["device"],
        use_rep = "X_dif",
        umap_key = lambda wildcards: f"X_umap_dif_nsteps{wildcards.num_steps}",
        n_neighbors = config["umap"]["n_neighbors"],
        n_pcs = config["umap"]["n_pcs"]
    script:
        "scripts/build_integrate_umap_celldiffusion.py"

# Rule: Build graph, integrate with GCN, and compute UMAP in one step (optimized to reduce file I/O)
rule build_integrate_umap_gcn:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/encoded.h5ad")
    output:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/gcn_nlayers{num_layers}.h5ad")
    resources:
        gpu=1
    threads: 1
    params:
        batch_key = config["evaluation"]["batch_key"],
        k = config["integration_loss_adj"]["k"],
        n_edges_per_node = config["integration_graph"]["n_edges_per_node"],
        k_mnn = config["integration_graph"]["k_mnn"],
        max_epoch = config["integration_gcn"]["max_epoch"],
        lr = config["integration_gcn"]["lr"],
        num_features_gcn = config["integration_gcn"]["num_features_gcn"],
        num_layers_gcn = lambda wildcards: int(wildcards.num_layers),
        dropout = config["integration_gcn"]["dropout"],
        device = config["device"],
        use_rep = "X_gcn",
        umap_key = lambda wildcards: f"X_umap_gcn_nlayers{wildcards.num_layers}",
        n_neighbors = config["umap"]["n_neighbors"],
        n_pcs = config["umap"]["n_pcs"]
    script:
        "scripts/build_integrate_umap_gcn.py"

# Rule: Evaluate neighbor purity for CellDiffusion results
rule evaluate_purity_celldiffusion:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/celldiffusion_nsteps{num_steps}.h5ad")
    output:
        csv = str(OUTPUT_BASE_DIR / "{dataset}/purity_celldiffusion_nsteps{num_steps}.csv")
    params:
        method = "CellDiffusion",
        network_layers = lambda wildcards: int(wildcards.num_steps),
        label_key = config["evaluation"]["label_key"],
        k = config["evaluation"]["k"]
    script:
        "scripts/evaluate_purity.py"

# Rule: Evaluate neighbor purity for GCN results
rule evaluate_purity_gcn:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/gcn_nlayers{num_layers}.h5ad")
    output:
        csv = str(OUTPUT_BASE_DIR / "{dataset}/purity_gcn_nlayers{num_layers}.csv")
    params:
        method = "GCN",
        network_layers = lambda wildcards: int(wildcards.num_layers),
        label_key = config["evaluation"]["label_key"],
        k = config["evaluation"]["k"]
    script:
        "scripts/evaluate_purity.py"

# Rule: Evaluate neighbor purity for CellDiffusion results (Mesenchymal lineage only)
rule evaluate_purity_celldiffusion_mesenchymal:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_embeddings.h5ad")
    output:
        csv = str(OUTPUT_BASE_DIR / "{dataset}/purity_celldiffusion_mesenchymal_nsteps{num_steps}.csv")
    params:
        method = "CellDiffusion",
        network_layers = lambda wildcards: int(wildcards.num_steps),
        label_key = config["evaluation"]["label_key"],
        k = config["evaluation"]["k"]
    script:
        "scripts/evaluate_purity_mesenchymal.py"

# Rule: Evaluate neighbor purity for GCN results (Mesenchymal lineage only)
rule evaluate_purity_gcn_mesenchymal:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_embeddings.h5ad")
    output:
        csv = str(OUTPUT_BASE_DIR / "{dataset}/purity_gcn_mesenchymal_nlayers{num_layers}.csv")
    params:
        method = "GCN",
        network_layers = lambda wildcards: int(wildcards.num_layers),
        label_key = config["evaluation"]["label_key"],
        k = config["evaluation"]["k"]
    script:
        "scripts/evaluate_purity_mesenchymal.py"

# Rule: Evaluate collapse metrics for CellDiffusion results
rule evaluate_collapse_metrics_celldiffusion:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/celldiffusion_nsteps{num_steps}.h5ad")
    output:
        csv = str(OUTPUT_BASE_DIR / "{dataset}/collapse_metrics_celldiffusion_nsteps{num_steps}.csv")
    params:
        method = "CellDiffusion",
        network_layers = lambda wildcards: int(wildcards.num_steps),
        k = config["evaluation"]["collapse_metrics"]["k"],
        variance_percentage = config["evaluation"]["collapse_metrics"]["variance_percentage"]
    script:
        "scripts/evaluate_collapse_metrics.py"

# Rule: Evaluate collapse metrics for GCN results
rule evaluate_collapse_metrics_gcn:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/gcn_nlayers{num_layers}.h5ad")
    output:
        csv = str(OUTPUT_BASE_DIR / "{dataset}/collapse_metrics_gcn_nlayers{num_layers}.csv")
    params:
        method = "GCN",
        network_layers = lambda wildcards: int(wildcards.num_layers),
        k = config["evaluation"]["collapse_metrics"]["k"],
        variance_percentage = config["evaluation"]["collapse_metrics"]["variance_percentage"]
    script:
        "scripts/evaluate_collapse_metrics.py"

# Rule: Aggregate all metrics
rule aggregate_metrics:
    input:
        csv_files = get_aggregate_metrics_files
    output:
        csv = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_metrics.csv")
    script:
        "scripts/aggregate_metrics.py"

# Rule: Aggregate collapse metrics
rule aggregate_collapse_metrics:
    input:
        csv_files = get_aggregate_collapse_metrics_files
    output:
        csv = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_collapse_metrics.csv")
    script:
        "scripts/aggregate_collapse_metrics.py"

# Rule: Aggregate all metrics for Mesenchymal lineage
rule aggregate_metrics_mesenchymal:
    input:
        csv_files = get_aggregate_metrics_mesenchymal_files
    output:
        csv = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_metrics_mesenchymal.csv")
    script:
        "scripts/aggregate_metrics_mesenchymal.py"

# Rule: Plot combined UMAP (CellDiffusion and GCN) for all layers in a multi-page PDF
# Reads from aggregated_embeddings.h5ad to reduce file I/O
rule plot_umap_combined:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_embeddings.h5ad")
    output:
        pdf = str(OUTPUT_BASE_DIR / "{dataset}/umap_combined_multipage.pdf")
    params:
        batch_key = config["evaluation"]["batch_key"],
        label_key = config["evaluation"]["label_key"]
    script:
        "scripts/plot_umap_combined.py"

# Rule: Aggregate all embeddings for SCIB evaluation
rule aggregate_embeddings:
    input:
        h5ad_files = get_aggregate_embeddings_files
    output:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_embeddings.h5ad")
    script:
        "scripts/aggregate_embeddings.py"

# Rule: SCIB evaluation
rule scib_evaluation:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_embeddings.h5ad")
    output:
        results = str(OUTPUT_BASE_DIR / "{dataset}/scib_benchmarker.pkl"),
        table = str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table.csv"),
        plot = str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table_plot.pdf")
    params:
        batch_key = config["evaluation"]["batch_key"],
        label_key = config["evaluation"]["label_key"],
        n_jobs = config["scib_evaluation"]["n_jobs"]
    script:
        "scripts/scib_evaluation.py"

# Rule: Plot SCIB evaluation line plot (aggregate scores vs network layers)
rule scib_evaluation_plot:
    input:
        csv = str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table.csv")
    output:
        pdf = str(OUTPUT_BASE_DIR / "{dataset}/scib_evaluation_lineplot.pdf")
    script:
        "scripts/scib_evaluation_plot.py"

# Rule: Plot collapse diagnostic (neighbor purity)
rule plot_collapse_diag:
    input:
        csv = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_metrics.csv")
    output:
        pdf = str(OUTPUT_BASE_DIR / "{dataset}/collapse_diagnostic_plot.pdf")
    script:
        "scripts/plot_collapse_diag.py"

# Rule: Plot collapse metrics (intrinsic dimension and variance explained)
rule plot_collapse_metrics:
    input:
        csv = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_collapse_metrics.csv")
    output:
        pdf = str(OUTPUT_BASE_DIR / "{dataset}/collapse_metrics_plot.pdf")
    script:
        "scripts/plot_collapse_metrics.py"

# Rule: Plot collapse diagnostic for Mesenchymal lineage (neighbor purity)
rule plot_collapse_diag_mesenchymal:
    input:
        csv = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_metrics_mesenchymal.csv")
    output:
        pdf = str(OUTPUT_BASE_DIR / "{dataset}/collapse_diagnostic_plot_mesenchymal.pdf")
    script:
        "scripts/plot_collapse_diag_mesenchymal.py"

# Rule: SCIB evaluation (Mesenchymal lineage only)
rule scib_evaluation_mesenchymal:
    input:
        h5ad = str(OUTPUT_BASE_DIR / "{dataset}/aggregated_embeddings.h5ad")
    output:
        results = str(OUTPUT_BASE_DIR / "{dataset}/scib_benchmarker_mesenchymal.pkl"),
        table = str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table_mesenchymal.csv"),
        plot = str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table_plot_mesenchymal.pdf")
    params:
        batch_key = config["evaluation"]["batch_key"],
        label_key = config["evaluation"]["label_key"],
        n_jobs = config["scib_evaluation"]["n_jobs"]
    script:
        "scripts/scib_evaluation_mesenchymal.py"

# Rule: Plot SCIB evaluation line plot (Mesenchymal lineage only)
rule scib_evaluation_plot_mesenchymal:
    input:
        csv = str(OUTPUT_BASE_DIR / "{dataset}/scib_results_table_mesenchymal.csv")
    output:
        pdf = str(OUTPUT_BASE_DIR / "{dataset}/scib_evaluation_lineplot_mesenchymal.pdf")
    script:
        "scripts/scib_evaluation_plot_mesenchymal.py"

